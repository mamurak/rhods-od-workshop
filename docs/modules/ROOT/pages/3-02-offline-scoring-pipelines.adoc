= 3.2 Offline Scoring Pipelines

We just saw how to run offline scoring in a notebook. It works, but just like in the real-time inference case, notebooks are not a good choice for long-running processes and production-like scenarios. In the case of offline scoring, it's best to define a _pipeline_ as a series of tasks and submit that pipeline to a backend system that runs and orchestrates the pipeline tasks on the cluster. Let's have a look at how this works with RHODS and Data Science Pipelines.

* In your workbench, double click on the `offline-scoring.pipeline` file. You can now see a graphical representation of the offline scoring pipeline within the Elyra Pipeline editor.

NOTE: Elyra is an extension of JupyterLab, which offers a graphical editor for pipelines that can be run on Data Science Pipelines.

* If you compare this pipeline with the previous offline scoring notebook, you will find the same steps. In fact, the pipeline includes the very same code since the pipeline tasks represent the underlying Python modules of the notebook steps. While the notebook defines a purely linear sequence of steps, the pipeline allows to parallelize tasks such as ingesting the raw data and downloading the trained model, both of which are independent of each other.

* Before you can submit this pipeline for execution, you will have to update a few configuration parameters via the `Open Panel` button in the top right corner of the pipeline editor window:
image::notebook/open-panel.png

** In *Data Volumes*, under *Persistent Volume Claim Name* enter your user ID.

** Under *Environment Variables*, copy and paste the access key and secret key of your S3 bucket into the corresponding fields. Under *S3_BUCKET_NAME*, enter your user ID.

* Save the pipeline (third button in top toolbar of the pipeline editor).

* Submit the pipeline by selecting `Run Pipeline` (second button in top toolbar). Change the pipeline name to your user ID to distinguish its run from those of the other workshop participants. Click `OK`.

* Revisit the RHODS Dashboard. In `Applications` -> `Enabled` -> `Data Science Pipelines`, select `Launch Application`. Authenticate and grant the requested permissions.

* In the Pipelines Dashboard, you can track all submitted pipelines including their versions. To monitor your pipeline, select `Runs` in the left menu. Each run represents an execution of a given pipeline. Find the run that you submitted and click on its name.

* You can now see a graphical representation of your pipeline which updates in real-time as the tasks are completed. You can select each task and monitor its progress. Once the final task is finished, you can verify its completion by finding the timestamped results table in your S3 bucket.

Congratulations! You have run your first offline scoring pipeline in RHODS, which concludes this lab.